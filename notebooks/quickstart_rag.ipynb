{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# ! pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai langchain-chroma bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG)\n",
    " ### RAG Q&A quickstart (LangChain Demo)\n",
    "  - 2 Main steps:\n",
    "     1. Indexing (VectorStore or similar store (FAISS) etc.)\n",
    "     2. Retrieval (Retrieve from the store and generate responses based on context)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' LangSmith, often known as the creator of the \"LangSmite\" project (a combination of coding and Minecraft), offers a unique approach to software testing that focuses on practical experimentation and learning through doing. While he may not directly provide a standardized service for testing like professional QA companies do, here\\'s how LangSmith\\'s methods can help with testing:\\n\\n1. Learning by building: By creating simple programs or tools in programming languages (like JavaScript, Python), you can learn to test the functionality of your code more effectively and efficiently. This hands-on approach helps developers better understand how their code behaves under different conditions and inputs.\\n\\n2. Community support: LangSmith has a large following on platforms like GitHub, where his projects are open-sourced. Engaging with this community can help you get valuable feedback from other experienced programmers who can provide advice or suggestions for testing strategies that have worked well in their own work.\\n\\n3. Creative problem solving: The LangSmite project encourages users to think creatively and apply problem-solving skills to create innovative tools, games, and projects within a controlled environment (Minecraft). This approach can be adapted to the testing process by designing unique test cases or experimenting with unconventional ways of approaching software bugs.\\n\\n4. Learning from LangSmith\\'s examples: By studying some of LangSmith\\'s programming projects, you might gain insights into how he tests his code and ensures it runs correctly in a variety of scenarios. This can serve as inspiration for your own testing strategies and help you think outside the box when approaching software testing challenges.\\n\\nIn summary, while LangSmith doesn\\'t directly offer services related to testing, adopting his experimental and hands-on approach may help improve your understanding and skills in developing effective test cases and procedures. Engaging with the community of like-minded programmers can also be valuable in helping you learn new techniques for software testing.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic llm use\n",
    "llm = Ollama(model='phi3')\n",
    "\n",
    "llm.invoke(\"how can langsmith help with testing ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a world class technical documentation writer.\"),\n",
    "        (\"user\", \"<|user|>{input}<|end|>\\n<|assistant|>\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a world class technical documentation writer.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='<|user|>{input}<|end|>\\n<|assistant|>'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" As a world-class technical documentation writer, LangSmith can assist in testing through the following ways:\\n\\n1. Documentation Creation: LangSmith provides comprehensive and clear guidelines for software tests that facilitate understanding of test objectives, procedures, and expected results. These detailed documents can help both manual and automated testers understand what is needed to perform a thorough evaluation effectively.\\n\\n2. Test Design Guidance: Utilizing LangSmith's expertise in writing technical documentation, you can create clear, well-structured test design specifications that outline the testing approach, criteria for success, expected inputs and outputs, as well as edge cases. This will aid in creating effective and efficient test plans and designs.\\n\\n3. Test Cases Development: LangSmith's expertise in documentation writing can be leveraged to create clear and concise test case descriptions that accurately reflect the purpose of each test scenario. Detailed instructions, expected results, as well as any necessary preconditions or setup for each test case will help ensure thorough coverage during testing.\\n\\n4. Test Result Reporting: LangSmith can assist in creating comprehensive and consistent documentation formats to record test results effectively. These reports should include a summary of the tests performed, pass/fail statuses, as well as any discrepancies or issues that were discovered during testing. This will help teams analyze performance data more efficiently and aid decision-making processes for future development efforts.\\n\\n5. Test Management: Through documentation writing skills, LangSmith can contribute to developing clear guidelines on how test results should be managed throughout the software development life cycle (SDLC), including criteria for success, methods for tracking progress, and ways to document lessons learned from testing activities. This will help ensure continuous improvement in quality assurance practices within your organization.\\n\\n6. Training Material Development: LangSmith can create training materials that explain how to perform tests based on the documentation created earlier. These materials may include instructional videos, test case walkthroughs or guides, and other resources designed to enhance a tester's understanding of testing concepts and procedures.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": 'how can langsmith help with testing ?'})\n",
    "\n",
    "# Still doesnt have a context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG pipeline components\n",
    " - Embeddings model\n",
    " - Vector index\n",
    " - Retrieval logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings model\n",
    "embed_model = OllamaEmbeddings(model='phi3')\n",
    "\n",
    "# Web based loader\n",
    "loader = WebBaseLoader(\n",
    "    'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
    "    bs_kwargs=dict(\n",
    "            parse_only=bs4.SoupStrainer(\n",
    "                class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# vectorstore (using local FAISS)\n",
    "vectorstore = FAISS.from_documents(documents, embedding=embed_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# create prompt from chat prompt template (Phi3-mini-4k-instruct)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "    Question : {input}\n",
    "    Context: {context}\n",
    "    Answer: \n",
    "    \"\"\"\n",
    "    # \"\"\"\n",
    "    # You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "    # <|user|>\n",
    "    # Question : {input}\n",
    "    # Context: {context}<|end|>\n",
    "    # <|assistant|>\n",
    "    # \"\"\"\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# RAG chain can also be created by usig the `create_stuff_documents_chain`:\n",
    "#            - We retrieve the documents first using a retriever.\n",
    "#            - Generally, we need to format_docs first and then stuff them together in a context and then add it in the context section of the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Chain of thought prompting, such as CoT (Wei et al. 2022), guides language models like LLMs to break down complex tasks into smaller steps and provide reasoning for their outputs, improving performance by encouraging the model's self-reflection based on feedback sequences.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke the rag chain\n",
    "rag_chain.invoke(\"What is chain of thought?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Task Decomposition is a problem solving strategy that breaks down complex tasks into smaller, manageable subtasks to make it easier for an agent or system to learn and execute the task efficiently. It involves designing algorithms that can handle each subtask independently while coordinating their efforts towards completing the overall objective.\n",
      "\n",
      "However, based on the provided context, there is no direct information about Task Decomposition. The discussed topics mainly relate to Model Fine-Tuning (CoH), Algorithm Distillation (AD), and fine-tuning Language Models for specific applications."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"What is Task Decomposition?\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding chat history\n",
    " - ***Prompt*** : Update prompt for historical chat support\n",
    " - ***Contextualization*** : Reformulate the question wrt the chat context. E.g. if asked someting like \"what is the second point ?\" after the model has produced different points given a question. The model wont know the context so we might be better off reformulating the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt from the langchain hub\n",
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contextualize the input query using a llm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "# prompts module, makes using prompts easy\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "# Taken from - https://python.langchain.com/v0.1/docs/use_cases/question_answering/chat_history/\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")]\n",
    ")\n",
    "\n",
    "# Create a history aware retriever\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a system input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "qa_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "\n",
    "# rag_chain = create_retrieval_chain(history_aware_retriever, qa_chain)\n",
    "\n",
    "rag_chain = (\n",
    "    history_aware_retriever\n",
    "    | qa_chain\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Task Decomposition is a technique where complex tasks are broken down into smaller, more manageable subtasks or components. One method involves using Chain of Thought (CoT) to guide an AI model's reasoning process step by step, while another approach fine-tunes language models with external tools and APIs for specific problem domains.\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "question = \"What is Task Decomposition?\"\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=question), ai_msg_1[\"answer\"]])\n",
    "\n",
    "second_question = \"What are common ways of doing it?\"\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print(ai_msg_2[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
